{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"week3- Federated Learning for Image Classification","provenance":[{"file_id":"https://github.com/tensorflow/federated/blob/v0.7.0/docs/tutorials/federated_learning_for_image_classification.ipynb","timestamp":1569929502406}],"collapsed_sections":[],"last_runtime":{"build_target":"","kind":"local"}},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qN8P0AnTnAhh"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"p8SrVqkmnDQv","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AftvNA5VMemJ"},"source":["# Federated Learning for Image Classification"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"coAumH42q9nz"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/federated/blob/v0.7.0/docs/tutorials/federated_learning_for_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.7.0/docs/tutorials/federated_learning_for_image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zs2LgZBOMt4M"},"source":["**NOTE**: This colab has been verified to work with the `0.7.0` version of the `tensorflow_federated` pip package, but the Tensorflow Federated project is still in pre-release development and may not work on `master`.\n","\n","In this tutorial, we use the classic MNIST training example to introduce the\n","Federated Learning (FL) API layer of TFF, `tff.learning` - a set of\n","higher-level interfaces that can be used to perform common types of federated\n","learning tasks, such as federated training, against user-supplied models\n","implemented in TensorFlow.\n","\n","This tutorial, and the Federated Learning API, are intended primarly for users\n","who want to plug their own TensorFlow models into TFF, treating the latter\n","mostly as a black box. For a more in-depth understanding of TFF and how to\n","implement your own federated learning algorithms, see the tutorials on the FC Core API - [Custom Federated Algorithms Part 1](custom_federated_algorithms_1.ipynb) and [Part 2](custom_federated_algorithms_2.ipynb).\n","\n","For more on `tff.learning`, continue with the\n","[Federated Learning for Text Generation](federated_learning_for_text_generation.ipynb),\n","tutorial which in addition to covering recurrent models, also demonstrates loading a\n","pre-trained serialized Keras model for refinement with federated learning\n","combined with evaluation using Keras."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MnUwFbCAKB2r"},"source":["## Before we start\n","\n","Before we start, please run the following to make sure that your environment is\n","correctly setup. If you don't see a greeting, please refer to the\n","[Installation](../install.md) guide for instructions."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZrGitA_KnRO0","outputId":"ef0b00cc-5db1-4933-d37a-702a1a7fc594","executionInfo":{"status":"ok","timestamp":1569987842668,"user_tz":-480,"elapsed":16219,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["#@test {\"skip\": true}\n","\n","# NOTE: If you are running a Jupyter notebook, and installing a locally built\n","# pip package, you may need to edit the following to point to the '.whl' file\n","# on your local filesystem.\n","\n","# NOTE: The high-performance executor components used in this tutorial are not\n","# yet included in the released pip package; you may need to compile from source.\n","!pip install folium\n","!pip install --quiet tensorflow_federated\n","!pip install --quiet  tf-nightly\n","\n","\n","# NOTE: Jupyter requires a patch to asyncio.\n","!pip install --upgrade nest_asyncio\n","import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: folium in /usr/local/lib/python3.6/dist-packages (0.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from folium) (2.21.0)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from folium) (0.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from folium) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from folium) (1.16.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from folium) (2.10.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (2019.9.11)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (1.24.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->folium) (1.1.1)\n","Requirement already up-to-date: nest_asyncio in /usr/local/lib/python3.6/dist-packages (1.2.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8BKyHkMxKHfV","outputId":"61cb8d76-ba84-408e-e304-4092c4f56c73","executionInfo":{"status":"ok","timestamp":1569987845134,"user_tz":-480,"elapsed":18664,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":385}},"source":["from __future__ import absolute_import, division, print_function\n","\n","import collections\n","import warnings\n","from six.moves import range\n","import numpy as np\n","import six\n","import tensorflow as tf\n","\n","warnings.simplefilter('ignore')\n","\n","tf.compat.v1.enable_v2_behavior()\n","\n","import tensorflow_federated as tff\n","\n","np.random.seed(0)\n","\n","NUM_CLIENTS = 10\n","\n","# NOTE: If the statement below fails, it means that you are\n","# using an older version of TFF without the high-performance\n","# executor stack. Call `tff.framework.set_default_executor()`\n","# instead to use the default reference runtime.\n","if six.PY3:\n","  tff.framework.set_default_executor(\n","      tff.framework.create_local_executor(NUM_CLIENTS))\n","\n","tff.federated_computation(lambda: 'Hello, World!')()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","\n","  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n","\n","  Please upgrade your code to TensorFlow 2.0:\n","    * https://www.tensorflow.org/beta/guide/migration_guide\n","\n","  Or install the latest stable TensorFlow 1.X release:\n","    * `pip install -U \"tensorflow==1.*\"`\n","\n","  Otherwise your code may be broken by the change.\n","\n","  \n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["b'Hello, World!'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5Cyy2AWbLMKj"},"source":["## Preparing the input data\n","\n","Let's start with the data. Federated learning requires a federated data set,\n","i.e., a collection of data from multiple users. Federated data is typically\n","non-[i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables),\n","which poses a unique set of challenges.\n","\n","In order to facilitate experimentation, we seeded the TFF repository with a few\n","datasets, including a federated version of MNIST that contains a version of the [original NIST dataset](https://www.nist.gov/srd/nist-special-database-19) that has been re-processed using [Leaf](https://github.com/TalwalkarLab/leaf) so that the data is keyed by the original writer of the digits. Since each writer has a unique style, this dataset exhibits the kind of non-i.i.d. behavior expected of federated datasets.\n","\n","Here's how we can load it."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NayDhCX6SjwE","colab":{}},"source":["#@test {\"output\": \"ignore\"}\n","emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yeX8BKgPfeFw"},"source":["The data sets returned by `load_data()` are instances of\n","`tff.simulation.ClientData`, an interface that allows you to enumerate the set\n","of users, to construct a `tf.data.Dataset` that represents the data of a\n","particular user, and to query the structure of individual elements. Here's how\n","you can use this interface to explore the content of the data set. Keep in mind\n","that while this interface allows you to iterate over clients ids, this is only a\n","feature of the simulation data. As you will see shortly, client identities are\n","not used by the federated learning framework - their only purpose is to allow\n","you to select subsets of the data for simulations."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kN4-U5nJgKig","outputId":"1a05ec56-5bfc-4f81-c918-b9a8bcd27d86","executionInfo":{"status":"ok","timestamp":1569987854600,"user_tz":-480,"elapsed":28086,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["len(emnist_train.client_ids)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3383"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZyCzIrSegT62","outputId":"09a2cb88-170a-4d90-e8d5-1752e32260ac","executionInfo":{"status":"ok","timestamp":1569987855064,"user_tz":-480,"elapsed":28527,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["emnist_train.output_types, emnist_train.output_shapes"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(OrderedDict([('label', tf.int32), ('pixels', tf.float32)]),\n"," OrderedDict([('label', TensorShape([])), ('pixels', TensorShape([28, 28]))]))"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EsvSXGEMgd9G","outputId":"9f91dff8-1c4b-4a7d-c200-ebc908bf23f9","executionInfo":{"status":"ok","timestamp":1569987855067,"user_tz":-480,"elapsed":28507,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["example_dataset = emnist_train.create_tf_dataset_for_client(\n","    emnist_train.client_ids[0])\n","\n","example_element = iter(example_dataset).next()\n","\n","example_element['label'].numpy()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OmLV0nfMg98V","outputId":"9a88706a-ea3a-48e0-89a6-89b85f5c6dd4","executionInfo":{"status":"ok","timestamp":1569987855745,"user_tz":-480,"elapsed":29137,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["#@test {\"output\": \"ignore\"}\n","from matplotlib import pyplot as plt\n","plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n","plt.grid('off')\n","_ = plt.show()"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lMd01egqy9we"},"source":["Since the data is already a `tf.data.Dataset`,  preprocessing can be accomplished using Dataset transformations. Here, we flatten the `28x28` images\n","into `784`-element arrays, shuffle the individual examples, organize them into batches, and renames the features\n","from `pixels` and `label` to `x` and `y` for use with Keras. We also throw in a\n","`repeat` over the data set to run several epochs."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cyG_BMraSuu_","colab":{}},"source":["NUM_EPOCHS = 10\n","BATCH_SIZE = 20\n","SHUFFLE_BUFFER = 500\n","\n","def preprocess(dataset):\n","\n","  def element_fn(element):\n","    return collections.OrderedDict([\n","        ('x', tf.reshape(element['pixels'], [-1])),\n","        ('y', tf.reshape(element['label'], [1])),\n","    ])\n","\n","  return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(\n","      SHUFFLE_BUFFER).batch(BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m9LXykN_jlJw"},"source":["Let's verify this worked."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VChB7LMQjkYz","outputId":"cd6d8cd1-cf00-4cf0-a1bf-c31900b803e6","executionInfo":{"status":"ok","timestamp":1569987855747,"user_tz":-480,"elapsed":29075,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":522}},"source":["#@test {\"output\": \"ignore\"}\n","preprocessed_example_dataset = preprocess(example_dataset)\n","\n","sample_batch = tf.nest.map_structure(\n","    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())\n","\n","sample_batch"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f6481044048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f6481044048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('x', array([[1., 1., 1., ..., 1., 1., 1.],\n","                     [1., 1., 1., ..., 1., 1., 1.],\n","                     [1., 1., 1., ..., 1., 1., 1.],\n","                     ...,\n","                     [1., 1., 1., ..., 1., 1., 1.],\n","                     [1., 1., 1., ..., 1., 1., 1.],\n","                     [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)),\n","             ('y', array([[5],\n","                     [1],\n","                     [6],\n","                     [6],\n","                     [1],\n","                     [6],\n","                     [7],\n","                     [1],\n","                     [0],\n","                     [3],\n","                     [0],\n","                     [9],\n","                     [7],\n","                     [4],\n","                     [9],\n","                     [3],\n","                     [4],\n","                     [9],\n","                     [6],\n","                     [8]], dtype=int32))])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JGsMvRQt9Agl"},"source":["We have almost all the building blocks in place to construct federated data\n","sets.\n","\n","One of the ways to feed federated data to TFF in a simulation is simply as a\n","Python list, with each element of the list holding the data of an individual\n","user, whether as a list or as a `tf.data.Dataset`. Since we already have\n","an interface that provides the latter, let's use it.\n","\n","Here's a simple helper function that will construct a list of datasets from the\n","given set of users as an input to a round of training or evaluation."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_PHMvHAI9xVc","colab":{}},"source":["def make_federated_data(client_data, client_ids):\n","  return [preprocess(client_data.create_tf_dataset_for_client(x))\n","          for x in client_ids]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0M9PfjOtAVqw"},"source":["Now, how do we choose clients?\n","\n","In a typical federated training scenario, we are dealing with potentially a very\n","large population of user devices, only a fraction of which may be available for\n","training at a given point in time. This is the case, for example, when the\n","client devices are mobile phones that participate in training only when plugged\n","into a power source, off a metered network, and otherwise idle.\n","\n","Of course, we are in a simulation environment, and all the data is locally\n","available. Typically then, when running simulations, we would simply sample a\n","random subset of the clients to be involved in each round of training, generally\n","different in each round.\n","\n","That said, as you can find out by studying the paper on the\n","[Federated Averaging](https://arxiv.org/abs/1602.05629) algorithm, achieving convergence in a system with randomly sampled\n","subsets of clients in each round can take a while, and it would be impractical\n","to have to run hundreds of rounds in this interactive tutorial.\n","\n","What we'll do instead is sample the set of clients once, and\n","reuse the same set across rounds to speed up convergence (intentionally\n","over-fitting to these few user's data). We leave it as an exercise for the\n","reader to modify this tutorial to simulate random sampling - it is fairly easy to\n","do (once you do, keep in mind that getting the model to converge may take a\n","while)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GZ6NYHxB8xer","outputId":"4ac41e6e-ce48-4ed0-98d3-7bc80079cc27","executionInfo":{"status":"ok","timestamp":1569987856095,"user_tz":-480,"elapsed":29376,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":405}},"source":["#@test {\"output\": \"ignore\"}\n","sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n","\n","federated_train_data = make_federated_data(emnist_train, sample_clients)\n","\n","len(federated_train_data), federated_train_data[0]"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f64810441e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f64810441e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f64b4d231e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f64b4d231e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f6480ff08c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f6480ff08c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f64807a02f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f64807a02f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f64807a0c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f64807a0c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f64807506a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f64807506a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f6490a77a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f6490a77a60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f648077b9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f648077b9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f6480731400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f6480731400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function preprocess.<locals>.element_fn at 0x7f6480731d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function preprocess.<locals>.element_fn at 0x7f6480731d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(10,\n"," <DatasetV1Adapter shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HOxq4tbi9m8-"},"source":["## Creating a model with Keras\n","\n","If you are using Keras, you likely already have code that constructs a Keras\n","model. Here's an example of a simple model that will suffice for our needs."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LYCsJGJFWbqt","colab":{}},"source":["def create_compiled_keras_model():\n","  model = tf.keras.models.Sequential([\n","      tf.keras.layers.Dense(\n","          10, activation=tf.nn.softmax, kernel_initializer='zeros', input_shape=(784,))])\n","  \n","  model.compile(\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NHdraKFH4OU2"},"source":["One critical note on `compile`. When used in the Federated Averaging algorithm,\n","as below, the `optimizer` is only half of of the total optimization algorithm,\n","as it is only used to compute local model updates on each client. The rest of\n","the algorithm involves how these updates are averaged over clients, and how they\n","are then applied to the global model at the server. In particular, this means\n","that the choice of optimizer and learning rate used here may need to be\n","different than the ones you have used to train the model on a standard i.i.d.\n","dataset. We recommend starting with regular SGD, possibly with a smaller\n","learning rate than usual. The learning rate we use here has not been carefully\n","tuned, feel free to experiment.\n","\n","In order to use any model with TFF, it needs to be wrapped in an instance of the\n","`tff.learning.Model` interface, which exposes methods to stamp the model's\n","forward pass, metadata properties, etc., similarly to Keras, but also introduces\n","additional elements, such as ways to control the process of computing federated\n","metrics. Let's not worry about this for now; if you have a compiled Keras model\n","like the one we've just defined above, you can have TFF wrap it for you by\n","invoking `tff.learning.from_compiled_keras_model`, passing the model and a\n","sample data batch as arguments, as shown below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q3ynrxd53HzY","colab":{}},"source":["def model_fn():\n","  keras_model = create_compiled_keras_model()\n","  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XJ5E3O18_JZ6"},"source":["## Training the model on federated data\n","\n","Now that we have a model wrapped as `tff.learning.Model` for use with TFF, we\n","can let TFF construct a Federated Averaging algorithm by invoking the helper\n","function `tff.learning.build_federated_averaging_process`, as follows.\n","\n","Keep in mind that the argument needs to be a constructor (such as `model_fn`\n","above), not an already-constructed instance, so that the construction of your\n","model can happen in a context controlled by TFF (if you're curious about the\n","reasons for this, we encourage you to read the follow-up tutorial on\n","[custom algorithms](custom_federated_algorithms_1.ipynb))."]},{"cell_type":"code","metadata":{"id":"1Otl-O4fS74a","colab_type":"code","outputId":"cbd48170-fffe-4ca8-cc4c-9647a5da3e42","executionInfo":{"status":"ok","timestamp":1569987859439,"user_tz":-480,"elapsed":32634,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["!pip list | grep tensorflow"],"execution_count":15,"outputs":[{"output_type":"stream","text":["mesh-tensorflow               0.0.5                \n","tensorflow                    1.14.0               \n","tensorflow-estimator          1.14.0               \n","tensorflow-federated          0.8.0                \n","tensorflow-hub                0.6.0                \n","tensorflow-metadata           0.14.0               \n","tensorflow-model-optimization 0.1.3                \n","tensorflow-probability        0.7.0                \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7SSK0yIAU2BH","colab_type":"code","outputId":"9bc7485b-8e4d-4f3f-befb-8844af8c0fc8","executionInfo":{"status":"ok","timestamp":1569987859440,"user_tz":-480,"elapsed":32610,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(tff.__version__)\n","print(tf.__version__)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["0.8.0\n","1.15.0-dev20190805\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sk6mjOfycX5N","outputId":"8c4eb39f-a1a5-4239-abac-13313fd7d334","executionInfo":{"status":"error","timestamp":1569988227915,"user_tz":-480,"elapsed":2374,"user":{"displayName":"滕景平","photoUrl":"","userId":"15023107628859585531"}},"colab":{"base_uri":"https://localhost:8080/","height":792}},"source":["#@test {\"output\": \"ignore\"}\n","iterative_process = tff.learning.build_federated_averaging_process(model_fn)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method _KerasModel.report_local_outputs of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647d3379e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method _KerasModel.report_local_outputs of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647d3379e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method _KerasModel.report_local_outputs of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647c1da9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method _KerasModel.report_local_outputs of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647c1da9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function _build_server_optimizer.<locals>.apply_delta at 0x7f647fdb2ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <function _build_server_optimizer.<locals>.apply_delta at 0x7f647fdb2ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method _KerasModel.report_local_outputs of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647c02ac50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method _KerasModel.report_local_outputs of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647c02ac50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method ClientFedAvg.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647af05400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method ClientFedAvg.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647af05400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <function ClientFedAvg.__call__.<locals>.reduce_fn at 0x7f647af6c620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <function ClientFedAvg.__call__.<locals>.reduce_fn at 0x7f647af6c620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method _TrainableKerasModel.train_on_batch of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647aedd4e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method _TrainableKerasModel.train_on_batch of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f647aedd4e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method _KerasModel.__init__.<locals>._WeightedMeanLossMetric.update_state of <tensorflow_federated.python.learning.keras_utils._KerasModel.__init__.<locals>._WeightedMeanLossMetric object at 0x7f647c02a8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING: Entity <bound method _KerasModel.__init__.<locals>._WeightedMeanLossMetric.update_state of <tensorflow_federated.python.learning.keras_utils._KerasModel.__init__.<locals>._WeightedMeanLossMetric object at 0x7f647c02a8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"error","ename":"OperatorNotAllowedInGraphError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-0fdb188570d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterative_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_federated_averaging_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/federated_averaging.py\u001b[0m in \u001b[0;36mbuild_federated_averaging_process\u001b[0;34m(model_fn, server_optimizer_fn, client_weight_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)\u001b[0m\n\u001b[1;32m    162\u001b[0m   return optimizer_utils.build_model_delta_optimizer_process(\n\u001b[1;32m    163\u001b[0m       \u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_fed_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_optimizer_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m       stateful_delta_aggregate_fn, stateful_model_broadcast_fn)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py\u001b[0m in \u001b[0;36mbuild_model_delta_optimizer_process\u001b[0;34m(model_fn, model_to_client_delta_fn, server_optimizer_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[0mserver_state_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_init_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_state_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtf_client_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_model_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"Performs client local model optimization.\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/computation_wrapper.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0marg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapper_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/computation_wrapper.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(fn, parameter_type, wrapper_fn)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Either we have a concrete parameter type, or this is no-arg function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mconcrete_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m   py_typecheck.check_type(concrete_fn, function_utils.ConcreteFunction,\n\u001b[1;32m    105\u001b[0m                           'value returned by the wrapper')\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/computation_wrapper_instances.py\u001b[0m in \u001b[0;36m_tf_wrapper_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mctx_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_stack_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   comp_pb, extra_type_spec = tensorflow_serialization.serialize_py_fn_as_tf_computation(\n\u001b[0;32m---> 44\u001b[0;31m       target_fn, parameter_type, ctx_stack)\n\u001b[0m\u001b[1;32m     45\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcomputation_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputationImpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_type_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/tensorflow_serialization.py\u001b[0m in \u001b[0;36mserialize_py_fn_as_tf_computation\u001b[0;34m(target, parameter_type, context_stack)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_computation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorFlowComputationContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0;31m# TODO(b/122081673): This needs to change for TF 2.0. We may also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/utils/function_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    582\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Args to be bound must be in scope.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_unpack_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m       \u001b[0;31m# An interceptor function that verifies the actual parameter before it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/utils/function_utils.py\u001b[0m in \u001b[0;36m_unpack_and_call\u001b[0;34m(fn, arg_types, kwarg_types, arg)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 element_value, expected_type)\n\u001b[1;32m    576\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(b/132888123): Consider other options to avoid possible bugs here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py\u001b[0m in \u001b[0;36mtf_client_delta\u001b[0;34m(tf_dataset, initial_model_weights)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \"\"\"\n\u001b[1;32m    373\u001b[0m     \u001b[0mclient_delta_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_client_delta_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mclient_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_delta_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_model_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    380\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    381\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 382\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2104\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1998\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    882\u001b[0m                                           converted_func)\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2612\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2613\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2614\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2615\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in converted code:\n    relative to /usr/local/lib/python3.6/dist-packages:\n\n    tensorflow_federated/python/tensorflow_libs/tensor_utils.py:115 zero_all_if_any_non_finite\n        if all_finite:\n    tensorflow_core/python/framework/ops.py:762 __bool__\n        self._disallow_bool_casting()\n    tensorflow_core/python/framework/ops.py:531 _disallow_bool_casting\n        \"using a `tf.Tensor` as a Python `bool`\")\n    tensorflow_core/python/framework/ops.py:518 _disallow_when_autograph_enabled\n        \" decorating it directly with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"f8FpvN2n67sm"},"source":["What just happened? TFF has constructed a pair of *federated computations* and\n","packaged them into a `tff.utils.IterativeProcess` in which these computations\n","are available as a pair of properties `initialize` and `next`.\n","\n","In a nutshell, *federated computations* are programs in TFF's internal language\n","that can express various federated algorithms (you can find more about this in\n","the [custom algorithms](custom_federated_algorithms_1.ipynb) tutorial). In this\n","case, the two computations generated and packed into `iterative_process`\n","implement [Federated Averaging](https://arxiv.org/abs/1602.05629).\n","\n","It is a goal of TFF to define computations in a way that they could be executed\n","in real federated learning settings, but currently only local execution\n","simulation runtime is implemented. To execute a computation in a simulator, you\n","simply invoke it like a Python function. This default interpreted environment is\n","not designed for high performance, but it will suffice for this tutorial; we\n","expect to provide higher-performance simulation runtimes to facilitate\n","larger-scale research in future releases.\n","\n","Let's start with the `initialize` computation. As is the case for all federated\n","computations, you can think of it as a function. The computation takes no\n","arguments, and returns one result - the representation of the state of the\n","Federated Averaging process on the server. While we don't want to dive into the\n","details of TFF, it may be instructive to see what this state looks like. You can\n","visualize it as follows."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z4pcfWsUBp_5","colab":{}},"source":["#@test {\"output\": \"ignore\"}\n","str(iterative_process.initialize.type_signature)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v1gbHQ_7BiyT"},"source":["While the above type signature may at first seem a bit cryptic, you can\n","recognize that the server state consists of a `model` (the initial model\n","parameters for MNIST that will be distributed to all devices), and\n","`optimizer_state` (additional information maintained by the server, such as the\n","number of rounds to use for hypermarameter schedules, etc.).\n","\n","Let's invoke the `initialize` computation to construct the server state."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6cagCWlZmcch","colab":{}},"source":["state = iterative_process.initialize()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TjjxTx9e_rMd"},"source":["The second of the pair of federated computations, `next`, represents a single\n","round of Federated Averaging, which consists of pushing the server state\n","(including the model parameters) to the clients, on-device training on their\n","local data, collecting and averaging model updates, and producing a new updated\n","model at the server.\n","\n","Conceptually, you can think of `next` as having a functional type signature that\n","looks as follows.\n","\n","```\n","SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n","```\n","\n","In particular, one should think about `next()` not as being a function that runs on a server, but rather being a declarative functional representation of the entire decentralized computation - some of the inputs are provided by the server (`SERVER_STATE`), but each participating device contributes its own local dataset.\n","\n","Let's run a single round of training and visualize the results. We can use the\n","federated data we've already generated above for a sample of users."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F3M_W9dDE6Tm","colab":{}},"source":["#@test {\"timeout\": 600, \"output\": \"ignore\"}\n","state, metrics = iterative_process.next(state, federated_train_data)\n","print('round  1, metrics={}'.format(metrics))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UmhReXt9G4A5"},"source":["Let's run a few more rounds. As noted earlier, typically at this point you would\n","pick a subset of your simulation data from a new randomly selected sample of\n","users for each round in order to simulate a realistic deployment in which users\n","continuously come and go, but in this interactive notebook, for the sake of\n","demonstration we'll just reuse the same users, so that the system converges\n","quickly."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qrJkQuCRJP9C","colab":{}},"source":["#@test {\"skip\": true}\n","for round_num in range(2, 11):\n","  state, metrics = iterative_process.next(state, federated_train_data)\n","  print('round {:2d}, metrics={}'.format(round_num, metrics))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"joHYzn9jcs0Y"},"source":["Training loss is decreasing after each round of federated training, indicating\n","the model is converging. There are some important caveats with these training\n","metrics, however, see the section on *Evaluation* later in this tutorial."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T4hneAcb-F2l"},"source":["## Customizing the model implementation\n","\n","Keras is the [recommended high-level model API for TensorFlow](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a), and we encourage using Keras models (via \n","`tff.learning.from_keras_model` or\n","`tff.learning.from_compiled_keras_model`) in TFF whenever possible.\n","\n","However, `tff.learning` provides a lower-level model interface, `tff.learning.Model`, that exposes the minimal functionality necessary for using a model for federated learning. Directly implementing this interface (possibly still using building blocks like `tf.keras.layers`) allows for maximum customization without modifying the internals of the federated learning algorithms.\n","\n","So let's do it all over again from scratch.\n","\n","### Defining model variables, forward pass, and metrics\n","\n","The first step is to identify the TensorFlow variables we're going to work with.\n","In order to make the following code more legible, let's define a data structure\n","to represent the entire set. This will include variables such as `weights` and\n","`bias` that we will train, as well as variables that will hold various\n","cumulative statistics and counters we will update during training, such as\n","`loss_sum`, `accuracy_sum`, and `num_examples`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uqRD72WQC4u1","colab":{}},"source":["MnistVariables = collections.namedtuple(\n","    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nkJfDcY5oXii"},"source":["Here's a method that creates the variables. For the sake of simplicity, we\n","represent all statistics as `tf.float32`, as that will eliminate the need for\n","type conversions at a later stage. Wrapping variable initializers as lambdas is\n","a requirement imposed by\n","[resource variables](https://www.tensorflow.org/api_docs/python/tf/enable_resource_variables)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H3GQHLNqCfMU","colab":{}},"source":["def create_mnist_variables():\n","  return MnistVariables(\n","      weights = tf.Variable(\n","          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),\n","          name='weights',\n","          trainable=True),\n","      bias = tf.Variable(\n","          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n","          name='bias',\n","          trainable=True),\n","      num_examples = tf.Variable(0.0, name='num_examples', trainable=False),\n","      loss_sum = tf.Variable(0.0, name='loss_sum', trainable=False),\n","      accuracy_sum = tf.Variable(0.0, name='accuracy_sum', trainable=False))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SrdnR0fAre-Q"},"source":["With the variables for model parameters and cumulative statistics in place, we\n","can now define the forward pass method that computes loss, emits predictions,\n","and updates the cumulative statistics for a single batch of input data, as\n","follows."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZYSRAl-KCvC7","colab":{}},"source":["def mnist_forward_pass(variables, batch):\n","  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n","  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n","\n","  flat_labels = tf.reshape(batch['y'], [-1])\n","  loss = -tf.reduce_mean(tf.reduce_sum(\n","      tf.one_hot(flat_labels, 10) * tf.log(y), reduction_indices=[1]))\n","  accuracy = tf.reduce_mean(\n","      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n","\n","  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n","\n","  variables.num_examples.assign_add(num_examples)\n","  variables.loss_sum.assign_add(loss * num_examples)\n","  variables.accuracy_sum.assign_add(accuracy * num_examples)\n","\n","  return loss, predictions"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-gm-yx2Mr_bl"},"source":["Next, we define a function that returns a set of local metrics, again using TensorFlow. These are the values (in addition to model updates, which are handled automatically) that are elligible to be aggregated to the server in a federated learning or evaluation process.\n","\n","Here, we simply return the average `loss` and `accuracy`, as well as the\n","`num_examples`, which we'll need to correctly weight the contributions from\n","different users when computing federated aggregates."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RkAZXhjGEekp","colab":{}},"source":["def get_local_mnist_metrics(variables):\n","  return collections.OrderedDict([\n","      ('num_examples', variables.num_examples),\n","      ('loss', variables.loss_sum / variables.num_examples),\n","      ('accuracy', variables.accuracy_sum / variables.num_examples)\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9ywGs1G-s1o3"},"source":["Finally, we need to determine how to aggregate the local metrics emitted by each\n","device via `get_local_mnist_metrics`. This is the only part of the code that isn't written in TensorFlow  - it's a *federated computation* expressed in TFF. If you'd like to\n","dig deeper, skim over the [custom algorithms](custom_federated_algorithms_1.ipynb)\n","tutorial, but in most applications, you won't really need to; variants of the\n","pattern shown below should suffice. Here's what it looks like:\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BMr2PwkfExFI","colab":{}},"source":["@tff.federated_computation\n","def aggregate_mnist_metrics_across_clients(metrics):\n","  return {\n","      'num_examples': tff.federated_sum(metrics.num_examples),\n","      'loss': tff.federated_mean(metrics.loss, metrics.num_examples),\n","      'accuracy': tff.federated_mean(metrics.accuracy, metrics.num_examples)\n","  }"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2rXZ3Hg44aeN"},"source":["The input `metrics` argument corresponds to the `OrderedDict` returned by `get_local_mnist_metrics` above, but critically the values are no longer `tf.Tensors` - they are \"boxed\" as `tff.Value`s, to make it clear you can no longer manipulate them using TensorFlow, but only using TFF's federated operators like `tff.federated_mean` and `tff.federated_sum`.  The returned\n","dictionary of global aggregates defines the set of metrics which will be available on the server.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7MXGAuQRvmcp"},"source":["### Constructing an instance of `tff.learning.Model`\n","\n","With all of the above in place, we are ready to construct a model representation\n","for use with TFF similar to one that's generated for you when you let TFF ingest\n","a Keras model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"blQGiTQFS9_r","colab":{}},"source":["class MnistModel(tff.learning.Model):\n","\n","  def __init__(self):\n","    self._variables = create_mnist_variables()\n","\n","  @property\n","  def trainable_variables(self):\n","    return [self._variables.weights, self._variables.bias]\n","\n","  @property\n","  def non_trainable_variables(self):\n","    return []\n","\n","  @property\n","  def local_variables(self):\n","    return [\n","        self._variables.num_examples, self._variables.loss_sum,\n","        self._variables.accuracy_sum\n","    ]\n","\n","  @property\n","  def input_spec(self):\n","    return collections.OrderedDict([('x', tf.TensorSpec([None, 784],\n","                                                        tf.float32)),\n","                                    ('y', tf.TensorSpec([None, 1], tf.int32))])\n","\n","  @tf.function\n","  def forward_pass(self, batch, training=True):\n","    del training\n","    loss, predictions = mnist_forward_pass(self._variables, batch)\n","    return tff.learning.BatchOutput(loss=loss, predictions=predictions)\n","\n","  @tf.function\n","  def report_local_outputs(self):\n","    return get_local_mnist_metrics(self._variables)\n","\n","  @property\n","  def federated_output_computation(self):\n","    return aggregate_mnist_metrics_across_clients"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sMN1AszMwLHL"},"source":["As you can see, the abstract methods and properties defined by\n","`tff.learning.Model` correspond to the code snippets in the preceding section\n","that introduced the variables and defined the loss and statistics.\n","\n","Here are a few points worth highlighting:\n","\n","*   All state that your model will use must be captured as TensorFlow variables,\n","    as TFF does not use Python at runtime (remember your code should be written\n","    such that it can be deployed to mobile devices; see the\n","    [custom algorithms](custom_federated_algorithms_1.ipynb) tutorial for a more\n","    in-depth commentary on the reasons).\n","*   Your model should describe what form of data it accepts (`input_spec`), as\n","    in general, TFF is a strongly-typed environment and wants to determine type\n","    signatures for all components. Declaring the format of your model's input is\n","    an essential part of it.\n","*   Although technically not required, we recommend wrapping all TensorFlow\n","    logic (forward pass, metric calculations, etc.) as `tf.function`s,\n","    as this helps ensure the TensorFlow can be serialized, and removes the need\n","    for explicit control dependencies.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9DVhXk2Bu-GU"},"source":["The above is sufficient for evaluation and algorithms like Federated SGD.\n","However, for Federated Averaging, we need to specify how the model should train\n","locally on each batch."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q1w7US3PFN2p","colab":{}},"source":["class MnistTrainableModel(MnistModel, tff.learning.TrainableModel):\n","\n","  @tf.function\n","  def train_on_batch(self, batch):\n","    output = self.forward_pass(batch)\n","    optimizer = tf.train.GradientDescentOptimizer(0.02)\n","    optimizer.minimize(output.loss, var_list=self.trainable_variables)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hVBugKP3yw03"},"source":["### Simulating federated training with the new model\n","\n","With all the above in place, the remainder of the process looks like what we've\n","seen already - just replace the model constructor with the constructor of our\n","new model class, and use the two federated computations in the iterative process\n","you created to cycle through training rounds."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FK3c8_leS9_t","colab":{}},"source":["iterative_process = tff.learning.build_federated_averaging_process(\n","    MnistTrainableModel)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Jv_LiggwS9_u","colab":{}},"source":["state = iterative_process.initialize()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PtOLElmzDPxs","colab":{}},"source":["#@test {\"timeout\": 600, \"output\": \"ignore\"}\n","state, metrics = iterative_process.next(state, federated_train_data)\n","print('round  1, metrics={}'.format(metrics))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gFkv0yJEGhue","colab":{}},"source":["#@test {\"skip\": true}\n","for round_num in range(2, 11):\n","  state, metrics = iterative_process.next(state, federated_train_data)\n","  print('round {:2d}, metrics={}'.format(round_num, metrics))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m7lz59lMJ0kj"},"source":["## Evaluation\n","\n","All of our experiments so far presented only federated training metrics - the\n","average metrics over all batches of data trained across all clients in the\n","round. This introduces the normal concerns about overfitting, especially since\n","we used the same set of clients on each round for simplicity, but there is an\n","additional notion of overfitting in training metrics specific to the Federated\n","Averaging algorithm. This is easiest to see if we imagine each client had a\n","single batch of data, and we train on that batch for many iterations (epochs).\n","In this case, the local model will quickly exactly fit to that one batch, and so\n","the local accuracy metric we average will approach 1.0. Thus, these training\n","metrics can be taken as a sign that training is progressing, but not much more.\n","\n","To perform evaluation on federated data, you can construct another *federated\n","computation* designed for just this purpose, using the\n","`tff.learning.build_federated_evaluation` function, and passing in your model\n","constructor as an argument. Note that unlike with Federated Averaging, where\n","we've used `MnistTrainableModel`, it suffices to pass the `MnistModel`.\n","Evaluation doesn't perform gradient descent, and there's no need to construct\n","optimizers.\n","\n","For experimentation and research, when a centralized test dataset is available,\n","[Federated Learning for Text Generation](federated_learning_for_text_generation.ipynb)\n","demonstrates another evaluation option: taking the trained weights from\n","federated learning, applying them to a standard Keras model, and then simply\n","calling `tf.keras.models.Model.evaluate()` on a centralized dataset."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nRiXyqnXM2VO","colab":{}},"source":["evaluation = tff.learning.build_federated_evaluation(MnistModel)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uwfINGoNQEuV"},"source":["You can inspect the abstract type signature of the evaluation function as follows."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3q5ueoO0NDNb","colab":{}},"source":["str(evaluation.type_signature)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XA3v7f2SQs6q"},"source":["No need to be concerned about the details at this point, just be aware that it\n","takes the following general form, similar to `tff.utils.IterativeProcess.next`\n","but with two important differences. First, we are not returning server state,\n","since evaluation doesn't modify the model or any other aspect of state - you can\n","think of it as stateless. Second, evaluation only needs the model, and doesn't\n","require any other part of server state that might be associated with training,\n","such as optimizer variables.\n","\n","```\n","SERVER_MODEL, FEDERATED_DATA -> TRAINING_METRICS\n","```\n","\n","Let's invoke evaluation on the latest state we arrived at during training. In\n","order to extract the latest trained model from the server state, you simply\n","access the `.model` member, as follows."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OX4Sk_uyOaYa","colab":{}},"source":["#@test {\"output\": \"ignore\"}\n","train_metrics = evaluation(state.model, federated_train_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UeEsdwJgRGMW"},"source":["Here's what we get. Note the numbers look marginally better than what was\n","reported by the last round of training above. By convention, the training\n","metrics reported by the iterative training process generally reflect the\n","performance of the model at the beginning of the training round, so the\n","evaluation metrics will always be one step ahead."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zwCy1IPxOfiT","colab":{}},"source":["#@test {\"output\": \"ignore\"}\n","str(train_metrics)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SpfgdNDoRjPy"},"source":["Now, let's compile a test sample of federated data and rerun evaluation on the\n","test data. The data will come from the same sample of real users, but from a\n","distinct held-out data set."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"in8vProVNc04","colab":{}},"source":["federated_test_data = make_federated_data(emnist_test, sample_clients)\n","\n","len(federated_test_data), federated_test_data[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ty-ZwfE0NJfV","colab":{}},"source":["#@test {\"output\": \"ignore\"}\n","test_metrics = evaluation(state.model, federated_test_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e5fGtIJYNqYH","colab":{}},"source":["#@test {\"output\": \"ignore\"}\n","str(test_metrics)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"67vYxrDWzRcj"},"source":["This concludes the tutorial. We encourage you to play with the\n","parameters (e.g., batch sizes, number of users, epochs, learning rates, etc.), to modify the code above to simulate training on random samples of users in\n","each round, and to explore the other tutorials we've developed."]}]}